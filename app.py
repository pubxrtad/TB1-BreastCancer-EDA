import streamlit as st
import pandas as pd
#import joblib
import numpy as np
#import seaborn as sns
#import matplotlib.pyplot as plt
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
    confusion_matrix,
    RocCurveDisplay
)
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler

#Configuraci√≥n de la p√°gina Streamlit
st.set_page_config(
    page_title='Predicci√≥n de C√°ncer de Mama: Aplicaci√≥n de CRISP-DM',
    page_icon="ü©ª",
    layout="wide",
    initial_sidebar_state="expanded"
)

#Cargar el modelo pre-entrenado
@st.cache_resource
def load_model_from_disk():
    model = joblib.load('optimized_rf_model.joblib')
    return model

model = load_model_from_disk()

#Cargar el DataFrame original para visualizaciones y preparaci√≥n de datos
@st.cache_data
def load_data_and_prepare():
    df_raw = pd.read_csv(r"/content/breast_cancer_wisconsin.csv")

    # Preprocesamiento de datos
    df_raw.columns = df_raw.columns.str.strip().str.lower().str.replace(' ', '_')
    df_raw = df_raw.rename(columns={'target': 'diagnosis'})
    # Mapping: 0 from original 'target' was malignant, 1 was benign.
    df_raw['diagnosis_binary'] = df_raw['diagnosis'].map({0: 1, 1: 0})
    X_for_model = df_raw.drop(columns=['diagnosis', 'diagnosis_binary'])
    y = df_raw['diagnosis_binary']

    return df_raw, X_for_model, y

df_for_plots, X_for_model_processed, y_target = load_data_and_prepare()

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_for_model_processed, y_target, test_size=0.2, random_state=42, stratify=y_target)

# Recalcular m√©tricas for the optimized RF model using the loaded 'model' (optimized_rf_model)
preds_optimized = model.predict(X_test)
probs_optimized = model.predict_proba(X_test)[:, 1]

accuracy_optimized = accuracy_score(y_test, preds_optimized)
precision_optimized = precision_score(y_test, preds_optimized)
recall_optimized = recall_score(y_test, preds_optimized)
f1_optimized = f1_score(y_test, preds_optimized)
auc_roc_optimized = roc_auc_score(y_test, probs_optimized)

# Recalculate predictions_df
predictions_df = pd.DataFrame({
    'Diagnostico actual': y_test,
    'Diagnostico predecido': preds_optimized,
    'Probabilidad de malignidad': probs_optimized
})
predictions_df['Diagnostico actual etiqueta'] = predictions_df['Diagnostico actual'].map({0: 'Benigno', 1: 'Maligno'})
predictions_df['Diagnostico predecido etiqueta'] = predictions_df['Diagnostico predecido'].map({0: 'Benigno', 1: 'Maligno'})

# Recalculate feature importances
feature_importances = model.feature_importances_
feature_names_for_input = X_for_model_processed.columns.tolist() # Obtener nombres de las 30 caracter√≠sticas
importances_df = pd.DataFrame({'variable': feature_names_for_input, 'importancia': feature_importances})
importances_df = importances_df.sort_values(by='importancia', ascending=False)
top_n_features = 5
top_features = importances_df.head(top_n_features)

# BARRA LATERAL
st.sidebar.title("‚û≤")
selection = st.sidebar.radio(
    "Ir a",
    [
        "Introducci√≥n",
        "Comparaci√≥n de Modelos",
        "M√©tricas del RF Optimizado",
        "An√°lisis de Variables Clave",
        "Evaluaci√≥n del RF Optimizado",
        "Predicci√≥n Interactiva",
        "Conclusiones Finales"
    ]
)

# CONTENIDO PRINCIPAL
st.title('‚ú¶ ·¥ò Ä·¥á·¥Ö…™·¥Ñ·¥Ñ…™√≥…¥ ·¥Ö·¥á ·¥Ñ√°…¥·¥Ñ·¥á Ä ·¥Ö·¥á ·¥ç·¥Ä·¥ç·¥Ä: ·¥Ä·¥ò ü…™·¥Ñ·¥Ä·¥Ñ…™√≥…¥ ·¥Ö·¥á ·¥Ñ Ä…™s·¥ò-·¥Ö·¥ç ‚ú¶')

if selection == "Introducci√≥n":
    st.subheader("‚û§ Problem√°tica")
    st.write("""
    Seg√∫n la OMS, el c√°ncer de mama es una de las principales causas de mortalidad en mujeres a nivel mundial. En 2022, se diagnosticaron cerca de 2,3 millones de casos nuevos en mujeres y se registraron aproximadamente 670 000 muertes. La detecci√≥n temprana puede aumentar las posibilidades de supervivencia, cuando se detecta en etapas iniciales, la tasa de curaci√≥n y √©xito del tratamiento es considerablemente m√°s alta.
    """)
    st.subheader("‚û§ Objetivos del Proyecto:")
    st.markdown("""
    Desarrollar un modelo de clasificaci√≥n basado que permita predecir la presencia de c√°ncer de mama a partir del dataset Breast Cancer Wisconsin, utilizando la metodolog√≠a CRISP-DM para asegurar un proceso estructurado desde el an√°lisis de datos hasta la evaluaci√≥n del rendimiento del modelo.
    """)
    st.subheader("‚û§ Objetivos Espec√≠ficos:")
    st.markdown("""
    - Realizar el entendimiento y exploraci√≥n inicial del dataset, identificando la distribuci√≥n de las variables,
      correlaciones relevantes y caracter√≠sticas representativas entre tumores benignos y malignos.
    - Preprocesar y preparar el conjunto de datos, aplicando limpieza, normalizaci√≥n y codificaci√≥n necesaria para
      garantizar la calidad del entrenamiento del modelo.
    - Entrenar y comparar distintos algoritmos de clasificaci√≥n, con el fin de determinar cu√°l presenta el mejor
      desempe√±o predictivo.
    - Evaluar los modelos mediante m√©tricas cuantitativas, priorizando el Recall para minimizar falsos negativos
      en el diagn√≥stico.
    - Implementar visualizaciones interpretativas que faciliten la comprensi√≥n de resultados para an√°lisis cl√≠nico
      y presentaci√≥n.
    - Construir una visualizaci√≥n HTML simple, donde el usuario pueda ingresar valores y obtener una predicci√≥n del
      modelo junto con gr√°ficos explicativos.
    """)
    st.image("/content/1_pxFCmhRFTighUn88baLcSA.png", caption="C√°ncer de Mama", use_container_width=False)

elif selection == "Comparaci√≥n de Modelos":
    st.header("Comparaci√≥n de Modelos de Clasificaci√≥n")
    st.write("Se evaluaron 3 modelos de clasificaci√≥n para determinar cu√°l ofrece el mejor rendimiento en la predicci√≥n del c√°ncer de mama.")

    df_results_data = {
        "Modelo": ["Logistic Regression", "Random Forest", "XGBoost"],
        "Accuracy": [0.938596, 0.973684, 0.964912],
        "Precision": [0.972973, 1.000000, 1.000000],
        "Recall": [0.857143, 0.928571, 0.904762],
        "F1-score": [0.911392, 0.962963, 0.950000],
        "AUC-ROC": [0.993717, 0.994378, 0.993056]
    }
    df_results = pd.DataFrame(df_results_data)
    st.dataframe(df_results)
    st.markdown("""
    - Los tres modelos muestran m√©tricas superiores al 93% en casi todos los indicadores, lo que es un rendimiento excelente.
    - **Random Forest** fue seleccionado como el mejor modelo debido a su combinaci√≥n de alta precisi√≥n y recall, minimizando los falsos negativos.
    """)

    # Matriz de calor de m√©tricas
    st.subheader("‚û§ Visualizaci√≥n Comparativa de M√©tricas")
    df_results_plot = df_results.set_index("Modelo")
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.heatmap(df_results_plot, annot=True, cmap="magma", fmt=".3f", ax=ax)
    ax.set_title("Comparaci√≥n de m√©tricas entre modelos")
    st.pyplot(fig)
    plt.close(fig)

elif selection == "M√©tricas del RF Optimizado":
    st.header("M√©tricas del Modelo Random Forest Optimizado")
    st.write("Rendimiento detallado del modelo Random Forest con hiperpar√°metros √≥ptimos en el conjunto de prueba.")

    metrics_df = pd.DataFrame({
        "M√©trica": ["Accuracy", "Precision", "Recall", "F1-score", "AUC-ROC"],
        "Valor": [accuracy_optimized, precision_optimized, recall_optimized, f1_optimized, auc_roc_optimized]
    })
    st.dataframe(metrics_df.set_index("M√©trica"))

    st.markdown("""
    - **Accuracy**: Proporci√≥n de predicciones correctas.
    - **Precision**: De las predicciones positivas, cu√°ntas fueron realmente positivas (minimiza falsos positivos).
    - **Recall (Sensibilidad)**: De todos los casos positivos reales, cu√°ntos fueron correctamente identificados (minimiza falsos negativos).
    - **F1-score**: Media arm√≥nica de precisi√≥n y recall.
    - **AUC-ROC**: Capacidad del modelo para distinguir entre clases.
    """)

    st.subheader("‚û§ Matriz de Confusi√≥n")
    cm = confusion_matrix(y_test, preds_optimized)
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='g',
                xticklabels=['Benigno (0)', 'Maligno (1)'],
                yticklabels=['Benigno (0)', 'Maligno (1)'], ax=ax)
    ax.set_title('Matriz de Confusi√≥n del RF Optimizado')
    ax.set_xlabel('Predicci√≥n')
    ax.set_ylabel('Real')
    st.pyplot(fig)
    plt.close(fig)

    st.markdown("""
    - La matriz de confusi√≥n muestra el n√∫mero de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos.
    - Un bajo n√∫mero de falsos negativos es lo prioritario en el diagn√≥stico de c√°ncer para evitar diagn√≥sticos err√≥neos.
    """)

elif selection == "An√°lisis de Variables Clave":
    st.header("Top 5 Variables M√°s Importantes")
    st.write("Las caracter√≠sticas que m√°s contribuyen a la predicci√≥n del modelo Random Forest.")

    st.dataframe(top_features.set_index('variable'))

    # Gr√°fico de barras de importancia de caracter√≠sticas
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.barplot(x='importancia', y='variable', data=top_features, palette='viridis', hue='variable', legend=False, ax=ax)
    ax.set_title(f'Top {top_n_features} Variables m√°s Importantes en el Random Forest Optimizado')
    ax.set_xlabel('Importancia')
    ax.set_ylabel('Variable')
    st.pyplot(fig)
    plt.close(fig)

    st.subheader("‚û§ Visualizaciones de Variables Clave")
    st.write("Exploraci√≥n visual de c√≥mo estas variables se relacionan con el diagn√≥stico.")

    # Scatter Plots
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Scatter Plot para worst_perimeter vs. worst_area
    sns.scatterplot(x='worst_perimeter', y='worst_area', hue='diagnosis_binary', data=df_for_plots, ax=axes[0], palette='viridis', s=50, alpha=0.7)
    axes[0].set_title('Scatter Plot: Worst Perimeter vs. Worst Area por Diagn√≥stico')
    axes[0].set_xlabel('Worst Perimeter')
    axes[0].set_ylabel('Worst Area')
    axes[0].legend(title='Diagn√≥stico (0:Benigno, 1:Maligno)')

    # Scatter Plot para mean_radius vs. mean_concave_points
    sns.scatterplot(x='mean_radius', y='mean_concave_points', hue='diagnosis_binary', data=df_for_plots, ax=axes[1], palette='viridis', s=50, alpha=0.7)
    axes[1].set_title('Scatter Plot: Mean Radius vs. Mean Concave Points por Diagn√≥stico')
    axes[1].set_xlabel('Mean Radius')
    axes[1].set_ylabel('Mean Concave Points')
    axes[1].legend(title='Diagn√≥stico (0:Benigno, 1:Maligno)')

    st.pyplot(fig)
    plt.close(fig)

    st.markdown("""
    - El primer gr√°fico muestra una fuerte correlaci√≥n positiva entre el peor per√≠metro y el peor √°rea. Esto indica que los tumores malignos tienden a tener c√©lulas significativamente m√°s grandes.
    - El segundo gr√°fico ilustra c√≥mo la combinaci√≥n de tama√±o e irregularidad es un fuerte indicador de malignidad.
    """)

    # Boxplots Comparativos
    st.subheader("‚û§ Boxplots Comparativos de Puntos C√≥ncavos")
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Boxplot para worst_concave_points
    sns.boxplot(x='diagnosis_binary', y='worst_concave_points', data=df_for_plots, ax=axes[0], palette='viridis', hue='diagnosis_binary', legend=False) # Agregado hue y legend
    axes[0].set_title('Distribuci√≥n de worst_concave_points por Diagn√≥stico')
    axes[0].set_xlabel('Diagn√≥stico (0: Benigno, 1: Maligno)')
    axes[0].set_ylabel('Worst Concave Points')

    # Boxplot para mean_concave_points
    sns.boxplot(x='diagnosis_binary', y='mean_concave_points', data=df_for_plots, ax=axes[1], palette='viridis', hue='diagnosis_binary', legend=False) # Agregado hue y legend
    axes[1].set_title('Distribuci√≥n de mean_concave_points por Diagn√≥stico')
    axes[1].set_xlabel('Diagn√≥stico (0: Benigno, 1: Maligno)')
    axes[1].set_ylabel('Mean Concave Points')

    st.pyplot(fig)
    plt.close(fig)

    st.markdown("""
    - Los boxplots muestran una diferencia marcada en la distribuci√≥n de los puntos c√≥ncavos, indicando mayor irregularidad y complejidad en los bordes celulares de los tumores malignos.
    """)

    # Histogramas Comparativos
    st.subheader("‚û§ Histogramas de Distribuci√≥n de Variables Clave")
    fig, axes = plt.subplots(1, 3, figsize=(20, 6))

    # Histograma para worst_perimeter
    sns.histplot(df_for_plots, x='worst_perimeter', hue='diagnosis_binary', kde=True, ax=axes[0], palette='viridis')
    axes[0].set_title('Distribuci√≥n de worst_perimeter por Diagn√≥stico')
    axes[0].set_xlabel('Worst Perimeter')
    axes[0].set_ylabel('Frecuencia')

    # Histograma para worst_area
    sns.histplot(df_for_plots, x='worst_area', hue='diagnosis_binary', kde=True, ax=axes[1], palette='viridis')
    axes[1].set_title('Distribuci√≥n de worst_area por Diagn√≥stico')
    axes[1].set_xlabel('Worst Area')
    axes[1].set_ylabel('Frecuencia')

    # Histograma para worst_radius
    sns.histplot(df_for_plots, x='worst_radius', hue='diagnosis_binary', kde=True, ax=axes[2], palette='viridis')
    axes[2].set_title('Distribuci√≥n de worst_radius por Diagn√≥stico')
    axes[2].set_xlabel('Worst Radius')
    axes[2].set_ylabel('Frecuencia')

    st.pyplot(fig)
    plt.close(fig)

    st.markdown("""
    - Los histogramas muestran una clara separaci√≥n en la distribuci√≥n de estas tres variables entre tumores benignos y malignos, confirmando su importancia.
    """)

elif selection == "Evaluaci√≥n del RF Optimizado":
    st.header("Evaluaci√≥n Detallada del Modelo Random Forest Optimizado")

    st.subheader("‚û§ Curva ROC")
    fig, ax = plt.subplots(figsize=(15, 4))
    roc_display = RocCurveDisplay.from_estimator(
        model, X_test, y_test, ax=ax, name='Optimized Random Forest'
    )
    ax.set_title('Curva ROC para el modelo Random Forest Optimizado')
    st.pyplot(fig)
    plt.close(fig)

    st.markdown("""
    - La curva ROC muestra una excelente capacidad del modelo para distinguir entre clases, con un √°rea bajo la curva (AUC) de aproximadamente **0.9944**.
    - Un AUC cercano a 1.0 indica que el modelo tiene una alta probabilidad de clasificar correctamente los casos.
    """)

    st.subheader("‚û§ Predicciones Detalladas")
    st.write("Muestra las predicciones del modelo en una parte del conjunto de prueba.")
    st.dataframe(predictions_df.head(10))

elif selection == "Predicci√≥n Interactiva":
    st.header("Realizar una Predicci√≥n de C√°ncer de Mama")
    st.write("Ajusta los valores de las caracter√≠sticas del tumor para obtener una predicci√≥n.")

    # Crear la interfaz de usuario para la entrada de datos
    user_input_data = {}
    st.sidebar.subheader("Valores de las Caracter√≠sticas del Tumor")

    # Obtener valores min, max y mean de X_for_model_processed para sliders
    min_vals = X_for_model_processed.min()
    max_vals = X_for_model_processed.max()
    mean_vals = X_for_model_processed.mean()

    for feature_name in feature_names_for_input:
        # Usar slider para float y number_input para int
        default_value = float(mean_vals[feature_name])
        min_value = float(min_vals[feature_name])
        max_value = float(max_vals[feature_name])

        # Asegurar que el valor por defecto est√© dentro del rango min/max
        if not (min_value <= default_value <= max_value):
            default_value = min_value # Fallback if mean is outside range for some reason

        user_input_data[feature_name] = st.sidebar.slider(
            f"{feature_name.replace('_', ' ').title()}",
            min_value=min_value,
            max_value=max_value,
            value=default_value,
            step=(max_value - min_value) / 100.0
        )

    input_df = pd.DataFrame([user_input_data])

    # Realizar la predicci√≥n
    prediction = model.predict(input_df)
    prediction_proba = model.predict_proba(input_df)[:, 1]

    st.subheader("Resultados de la Predicci√≥n:")
    if prediction[0] == 1:
        st.error(f"El tumor es **Maligno** con una probabilidad del **{prediction_proba[0]*100:.2f}%**.")
        st.markdown("<p style='color:red;'>Se recomienda una evaluaci√≥n m√©dica urgente.</p>", unsafe_allow_html=True)
    else:
        st.success(f"El tumor es **Benigno** con una probabilidad del **{(1 - prediction_proba[0])*100:.2f}%**.")
        st.markdown("<p style='color:green;'>El riesgo de malignidad es bajo, pero se recomienda seguimiento m√©dico.</p>", unsafe_allow_html=True)

    st.write("---")
    st.subheader("Valores de Entrada:")
    st.dataframe(input_df.T.rename(columns={0: 'Valor Ingresado'}))

elif selection == "Conclusiones Finales":
    st.header("Conclusiones y Recomendaciones")
    st.write("""
    El desarrollo de este proyecto siguiendo la metodolog√≠a CRISP-DM ha permitido identificar
    que el modelo **Random Forest** ofrece un rendimiento excepcional para la predicci√≥n
    del c√°ncer de mama, con alta precisi√≥n y un muy bajo n√∫mero de falsos negativos.
    """)

    st.subheader("Hallazgos Clave:")
    st.markdown("""
    - Las caracter√≠sticas morfol√≥gicas como el per√≠metro, √°rea, radio y los puntos c√≥ncavos de las c√©lulas son los indicadores m√°s influyentes en el diagn√≥stico.
    - El modelo Random Forest supera a la Regresi√≥n Log√≠stica y XGBoost en este contexto.
    - La alta m√©trica de Recall (0.9286) y AUC-ROC (0.9944) demuestran la robustez del modelo.
    """)

    st.subheader("Recomendaciones:")
    st.markdown("""
    - Probar el modelo con conjuntos de datos de diferentes fuentes para asegurar su generalizaci√≥n.
    - Aunque Random Forest es menos interpretable que otros modelos, t√©cnicas como SHAP o LIME podr√≠an ofrecer mayor transparencia.
    - Explorar la integraci√≥n de este modelo en sistemas de apoyo a la decisi√≥n cl√≠nica para asistir a los profesionales de la salud.
    - Monitorear el rendimiento del modelo en producci√≥n y reentrenarlo peri√≥dicamente con nuevos datos.
    """)

    st.info("Gracias por revisar este dashboard. ¬°La detecci√≥n temprana salva vidas!")
